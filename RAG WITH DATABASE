# ============================================================
#   MULTI-PDF RAG CHAT APP (UTF-8 SAFE VERSION FOR WINDOWS)
# ============================================================

from flask import Flask, render_template, request, jsonify
import os, uuid, json
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone, ServerlessSpec
import ollama

# ============================================================
#   LOAD ENV + CONFIG
# ============================================================

load_dotenv()

# âš  Replace with your real key
FALLBACK_PINECONE_KEY = "pcsk_5xbrB1_AxxZTUaQmxNnwuw1aXLh2b3hMtLQVQNzFxKRZ4J7b51eGvYCKua7tpH9wMdc4zB"

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY") or FALLBACK_PINECONE_KEY
MODEL_NAME = "llama3.2"
EMBEDDER_MODEL = "all-MiniLM-L6-v2"

INDEX_NAME = "rag-index"
NAMESPACE = "pdf-chunks"
UPLOAD_DIR = "uploads"

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs("templates", exist_ok=True)
os.makedirs("static", exist_ok=True)

history = []
uploaded_files = []

# ============================================================
#   INIT MODELS + PINECONE
# ============================================================

embedder = SentenceTransformer(EMBEDDER_MODEL)
pc = Pinecone(api_key=PINECONE_API_KEY)

if INDEX_NAME not in [i.name for i in pc.list_indexes()]:
    pc.create_index(
        name=INDEX_NAME,
        dimension=384,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

index = pc.Index(INDEX_NAME)

# ============================================================
#   PDF PROCESSING FUNCTIONS
# ============================================================

def extract_text(path):
    try:
        reader = PdfReader(path)
        text = ""
        for p in reader.pages:
            t = p.extract_text()
            if t:
                text += t + "\n"
        return text.strip()
    except Exception:
        return ""

def chunk_text(text, size=350, overlap=80):
    words = text.split()
    chunks = []
    i = 0
    while i < len(words):
        chunks.append(" ".join(words[i:i+size]))
        i += size - overlap
    return chunks or ["EMPTY DOCUMENT"]

def store_chunks(chunks, pdf_name):
    embeddings = embedder.encode(chunks)
    vectors = [
        (str(uuid.uuid4()), emb.tolist(), {"text": chunk, "file": pdf_name})
        for chunk, emb in zip(chunks, embeddings)
    ]
    index.upsert(vectors=vectors, namespace=NAMESPACE)
    return len(vectors)

def delete_pdf_vectors(pdf_name):
    res = index.query(vector=[0]*384, top_k=5000, include_metadata=True, namespace=NAMESPACE)
    ids = [m["id"] for m in res["matches"] if m["metadata"].get("file") == pdf_name]
    if ids:
        index.delete(ids=ids, namespace=NAMESPACE)
    return len(ids)

# ============================================================
#   AI FUNCTIONS
# ============================================================

def retrieve_context(q):
    q_emb = embedder.encode(q).tolist()
    res = index.query(vector=q_emb, top_k=7, include_metadata=True, namespace=NAMESPACE)
    return "\n\n".join(m["metadata"]["text"] for m in res["matches"])

def ask_llm(model, prompt):
    r = ollama.generate(model=model, prompt=prompt)
    return r["response"]

# ============================================================
#   FLASK APP
# ============================================================

app = Flask(__name__)

@app.route("/")
def home():
    return render_template("index.html")

# ============================================================
#   MULTIPLE PDF UPLOAD
# ============================================================

@app.route("/upload", methods=["POST"])
def upload():
    global uploaded_files

    if "pdfs" not in request.files:
        return jsonify({"error": "No files"}), 400

    files = request.files.getlist("pdfs")

    results = []

    for pdf in files:
        name = pdf.filename
        if not name.lower().endswith(".pdf"):
            results.append({"file": name, "error": "Not a PDF"})
            continue

        path = os.path.join(UPLOAD_DIR, name)
        pdf.save(path)

        text = extract_text(path)
        if len(text) < 20:
            results.append({"file": name, "error": "Unreadable PDF"})
            continue

        chunks = chunk_text(text)
        count = store_chunks(chunks, name)
        uploaded_files.append(name)
        results.append({"file": name, "message": f"Stored {count} chunks"})

    return jsonify({"uploaded": results, "files": uploaded_files})

# ============================================================
#   REMOVE ONE PDF
# ============================================================

@app.route("/remove_pdf", methods=["POST"])
def remove_pdf():
    global uploaded_files
    name = request.form.get("file", "")

    if name not in uploaded_files:
        return jsonify({"error": "File not found"}), 400

    deleted = delete_pdf_vectors(name)

    try:
        os.remove(os.path.join(UPLOAD_DIR, name))
    except:
        pass

    uploaded_files.remove(name)
    return jsonify({"message": f"Removed {name} ({deleted} chunks)", "files": uploaded_files})

# ============================================================
#   REMOVE ALL PDFS
# ============================================================

@app.route("/remove_all", methods=["POST"])
def remove_all():
    global uploaded_files
    index.delete(delete_all=True, namespace=NAMESPACE)
    uploaded_files = []

    for f in os.listdir(UPLOAD_DIR):
        os.remove(os.path.join(UPLOAD_DIR, f))

    return jsonify({"message": "All PDFs removed", "files": []})

# ============================================================
#   ASK QUESTION
# ============================================================

@app.route("/ask", methods=["POST"])
def ask():
    q = request.form.get("question", "")
    model = request.form.get("model", MODEL_NAME)

    context = retrieve_context(q)

    prompt = f"""
Use ONLY the context. If answer not found, reply "I don't know".

CONTEXT:
{context}

QUESTION:
{q}

ANSWER:
"""

    answer = ask_llm(model, prompt)
    history.append({"q": q, "a": answer})

    return jsonify({"answer": answer, "history": history})

# ============================================================
#   WRITE HTML (UTF-8 SAFE)
# ============================================================

with open("templates/index.html", "w", encoding="utf-8") as f:
    f.write("""
<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Multi-PDF RAG Chat</title>
<link rel="stylesheet" href="/static/style.css">
</head>
<body>

<div class="container">

<div class="sidebar">
    <h2>Uploaded PDFs</h2>
    <div id="filelist"></div>
    <button onclick="removeAll()">Remove All</button>

    <h2>History</h2>
    <div id="history"></div>
</div>

<div class="main">
    <div id="response">Upload PDFs to begin</div>

    <div class="input-area">
        <input type="file" id="pdfs" multiple hidden>
        <button onclick="document.getElementById('pdfs').click()">Upload PDFs</button>

        <select id="model">
            <option value="llama3.2">llama3.2</option>
            <option value="mistral">mistral</option>
        </select>

        <input id="q" type="text" placeholder="Ask something...">
        <button onclick="send()">Send</button>
    </div>
</div>

</div>

<script>
document.getElementById("pdfs").onchange = async () => {
    const files = document.getElementById("pdfs").files;
    let fd = new FormData();
    for (let f of files) fd.append("pdfs", f);

    const r = await fetch("/upload", {method:"POST", body:fd});
    const j = await r.json();

    let out = "";
    j.uploaded.forEach(u=>{
        if (u.error) out += "<div class='msg error'>" + u.file + ": " + u.error + "</div>";
        else out += "<div class='msg success'>" + u.file + ": " + u.message + "</div>";
    });

    document.getElementById("response").innerHTML = out;
    updateFileList(j.files);
};

async function removeFile(name){
    let fd = new FormData();
    fd.append("file", name);
    const r = await fetch("/remove_pdf", {method:"POST", body:fd});
    const j = await r.json();
    updateFileList(j.files);
    document.getElementById("response").innerHTML = j.message;
}

async function removeAll(){
    const r = await fetch("/remove_all", {method:"POST"});
    const j = await r.json();
    updateFileList([]);
    document.getElementById("response").innerHTML = j.message;
}

async function send(){
    const fd = new FormData();
    fd.append("question", document.getElementById("q").value);
    fd.append("model", document.getElementById("model").value);

    const r = await fetch("/ask", {method:"POST", body:fd});
    const j = await r.json();

    add("You: " + document.getElementById("q").value, "q");
    add("Answer: " + j.answer, "a");

    updateHistory(j.history);
}

function add(t,c){
    const d=document.createElement("div");
    d.className="msg "+c;
    d.innerHTML=t;
    document.getElementById("response").appendChild(d);
}

function updateHistory(h){
    const div=document.getElementById("history");
    div.innerHTML="";
    h.forEach(x=>{
        let d=document.createElement("div");
        d.innerText=x.q;
        div.appendChild(d);
    });
}

function updateFileList(files){
    const fl=document.getElementById("filelist");
    fl.innerHTML="";
    files.forEach(f=>{
        fl.innerHTML += "<div class='file-item'>" + f + " <button onclick=\\\"removeFile('" + f + "')\\\">X</button></div>";
    });
}
</script>

</body>
</html>
    """)

# ============================================================
#   CSS (UTF-8 SAFE)
# ============================================================

with open("static/style.css", "w", encoding="utf-8") as f:
    f.write("""
body {background:#111;color:#eee;margin:0;font-family:Arial;}
.container {display:flex;height:100vh;}
.sidebar {width:280px;background:#222;padding:10px;overflow-y:auto;}
.main {flex:1;display:flex;flex-direction:column;}
#response {flex:1;padding:15px;overflow-y:auto;background:#111;}

.input-area {padding:10px;background:#222;display:flex;gap:10px;}
button,input,select {padding:10px;border:none;border-radius:6px;background:#333;color:white;}

.msg {padding:10px;margin:10px 0;border-radius:5px;}
.success {background:#004400;color:#90ff90;}
.error {background:#440000;color:#ff9090;}
.q {background:#003300;}
.a {background:#330000;}

.file-item {background:#333;padding:5px;margin:5px 0;border-radius:5px;display:flex;justify-content:space-between;}
    """)

# ============================================================
#   RUN SERVER
# ============================================================

if __name__ == "__main__":
    print("ðŸš€ Multi-PDF RAG running at http://127.0.0.1:5000/")
    app.run(host="0.0.0.0", port=5000, debug=True)
